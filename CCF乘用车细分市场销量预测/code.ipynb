{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "import gc\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "#from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error as mse  # 评测标准\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import datetime\n",
    "import time\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path  = './input/'\n",
    "train_sales  = pd.read_csv(path+'train_sales_data.csv')  #  销量训练集 <-标签\n",
    "train_search = pd.read_csv(path+'train_search_data.csv') # 搜索量训练集\n",
    "train_user   = pd.read_csv(path+'train_user_reply_data.csv') # 评论训练集\n",
    "evaluation_public = pd.read_csv(path+'evaluation_public.csv') # 测试集\n",
    "submit_example    = pd.read_csv(path+'submit_example.csv') # 样例集\n",
    "data = pd.concat([train_sales, evaluation_public], ignore_index=True) # 将销量训练集与预测集连接\n",
    "# print(data)\n",
    "# data.to_csv('./data2.csv',index=False, encoding='gb2312')\n",
    "data = data.merge(train_search, 'left', on=['province', 'adcode', 'model', 'regYear', 'regMonth'])\n",
    "data = data.merge(train_user, 'left', on=['model', 'regYear', 'regMonth']) # 左连接，将该车型相同时间的其他特征连接起来\n",
    "\n",
    "data['label'] = data['salesVolume'] # <-标签列\n",
    "data['id'] = data['id'].fillna(0).astype(int) # 空值 用0填充\n",
    "# map映射   \n",
    "# drop_duplicates 对model(SUV（车型编码）-1车身类型[最细致的一个特征])去重，去重后便于map标号\n",
    "\n",
    "data['bodyType'] = data['model'].map(train_sales.drop_duplicates('model').set_index('model')['bodyType'])\n",
    "#data['bodyType'].to_csv('./data3.csv',index=False, encoding='gb2312')\n",
    "\n",
    "#LabelEncoder\n",
    "for i in ['bodyType', 'model']:\n",
    "    data[i] = data[i].map(dict(zip(data[i].unique(), range(data[i].nunique()))))\n",
    "data['mt'] = (data['regYear'] - 2016) * 12 + data['regMonth']\n",
    "data.to_csv('./data4.csv',index=False, encoding='gb2312')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stat_feature(df_):   \n",
    "    df = df_.copy()\n",
    "    stat_feat = []\n",
    "    df['model_adcode'] = df['adcode'] + df['model']\n",
    "    df['model_adcode_mt'] = df['model_adcode'] * 100 + df['mt']\n",
    "    for col in tqdm(['label','popularity']):\n",
    "        # shift\n",
    "        for i in [1,2,3,4,5,6,7,8,9,10,11,12]:\n",
    "            stat_feat.append('shift_model_adcode_mt_{}_{}'.format(col,i))\n",
    "            df['model_adcode_mt_{}_{}'.format(col,i)] = df['model_adcode_mt'] + i\n",
    "            df_last = df[~df[col].isnull()].set_index('model_adcode_mt_{}_{}'.format(col,i))\n",
    "            df['shift_model_adcode_mt_{}_{}'.format(col,i)] = df['model_adcode_mt'].map(df_last[col])    \n",
    "    return df,stat_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(data, pred='pred_label', label='label', group='model'):\n",
    "    data['pred_label'] = data['pred_label'].apply(lambda x: 0 if x < 0 else x).round().astype(int)\n",
    "    data_agg = data.groupby('model').agg({\n",
    "        pred:  list,\n",
    "        label: [list, 'mean']\n",
    "    }).reset_index()\n",
    "    data_agg.columns = ['_'.join(col).strip() for col in data_agg.columns]\n",
    "    nrmse_score = []\n",
    "    for raw in data_agg[['{0}_list'.format(pred), '{0}_list'.format(label), '{0}_mean'.format(label)]].values:\n",
    "        nrmse_score.append(\n",
    "            mse(raw[0], raw[1]) ** 0.5 / raw[2]\n",
    "        )\n",
    "    print(1 - np.mean(nrmse_score))\n",
    "    return 1 - np.mean(nrmse_score)\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_type(train_x,train_y,valid_x,valid_y,m_type='lgb'):   \n",
    "    if m_type == 'lgb':\n",
    "        model = lgb.LGBMRegressor(\n",
    "                                num_leaves=2**5-1, reg_alpha=0.25, reg_lambda=0.25, objective='mse',\n",
    "                                max_depth=-1, learning_rate=0.05, min_child_samples=5, random_state=2019,\n",
    "                                n_estimators=2000, subsample=0.9, colsample_bytree=0.7,\n",
    "                                )\n",
    "        model.fit(train_x, train_y, \n",
    "              eval_set=[(train_x, train_y),(valid_x, valid_y)], \n",
    "              categorical_feature=cate_feat, \n",
    "              early_stopping_rounds=100, verbose=100)      \n",
    "    elif m_type == 'xgb':\n",
    "        model = xgb.XGBRegressor(\n",
    "                                max_depth=5 , learning_rate=0.05, n_estimators=2000, \n",
    "                                objective='reg:gamma', tree_method = 'hist',subsample=0.9, \n",
    "                                colsample_bytree=0.7, min_child_samples=5,eval_metric = 'rmse' \n",
    "                                )\n",
    "        model.fit(train_x, train_y, \n",
    "              eval_set=[(train_x, train_y),(valid_x, valid_y)], \n",
    "              early_stopping_rounds=100, verbose=100)   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_model(df_, m, m_type='lgb'):\n",
    "    df = df_.copy()\n",
    "    # 数据集划分\n",
    "    st = 13\n",
    "    all_idx   = (df['mt'].between(st , m-1))\n",
    "    train_idx = (df['mt'].between(st , m-5))\n",
    "    valid_idx = (df['mt'].between(m-4, m-4))\n",
    "    test_idx  = (df['mt'].between(m  , m  ))\n",
    "    print('all_idx  :',st ,m-1)\n",
    "    print('train_idx:',st ,m-5)\n",
    "    print('valid_idx:',m-4,m-4)\n",
    "    print('test_idx :',m  ,m  )  \n",
    "    # 最终确认\n",
    "    train_x = df[train_idx][features]\n",
    "    train_y = df[train_idx]['label']\n",
    "    valid_x = df[valid_idx][features]\n",
    "    valid_y = df[valid_idx]['label']   \n",
    "    # get model\n",
    "    model = get_model_type(train_x,train_y,valid_x,valid_y,m_type)  \n",
    "    # offline\n",
    "    df['pred_label'] = model.predict(df[features])\n",
    "    best_score = score(df[valid_idx]) \n",
    "    # online\n",
    "    if m_type == 'lgb':\n",
    "        model.n_estimators = model.best_iteration_ + 100\n",
    "        model.fit(df[all_idx][features], df[all_idx]['label'], categorical_feature=cate_feat)\n",
    "    elif m_type == 'xgb':\n",
    "        model.n_estimators = model.best_iteration + 100\n",
    "        model.fit(df[all_idx][features], df[all_idx]['label'])\n",
    "    df['forecastVolum'] = model.predict(df[features]) \n",
    "    print('valid mean:',df[valid_idx]['pred_label'].mean())\n",
    "    print('true  mean:',df[valid_idx]['label'].mean())\n",
    "    print('test  mean:',df[test_idx]['forecastVolum'].mean())\n",
    "    # 阶段结果\n",
    "    sub = df[test_idx][['id']]\n",
    "    sub['forecastVolum'] = df[test_idx]['forecastVolum'].apply(lambda x: 0 if x < 0 else x).round().astype(int)  \n",
    "    return sub,df[valid_idx]['pred_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.70it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 28.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 29\n",
      "all_idx  : 13 24\n",
      "train_idx: 13 20\n",
      "valid_idx: 21 21\n",
      "test_idx : 25 25\n",
      "[0]\tvalidation_0-rmse:841.375\tvalidation_1-rmse:1046.8\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-rmse:800.25\tvalidation_1-rmse:1004.68\n",
      "[199]\tvalidation_0-rmse:260.992\tvalidation_1-rmse:373.604\n",
      "0.7060436029133734\n",
      "valid mean: 543.93024\n",
      "true  mean: 649.3121212121212\n",
      "test  mean: 460.5905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.53it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 31.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 29\n",
      "all_idx  : 13 25\n",
      "train_idx: 13 21\n",
      "valid_idx: 22 22\n",
      "test_idx : 26 26\n",
      "[0]\tvalidation_0-rmse:866.608\tvalidation_1-rmse:1007.37\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-rmse:825.42\tvalidation_1-rmse:966.248\n",
      "[199]\tvalidation_0-rmse:269.098\tvalidation_1-rmse:403.121\n",
      "0.5904416959454815\n",
      "valid mean: 441.86932\n",
      "true  mean: 616.5537878787878\n",
      "test  mean: 328.8417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.98it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 31.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 29\n",
      "all_idx  : 13 26\n",
      "train_idx: 13 22\n",
      "valid_idx: 23 23\n",
      "test_idx : 27 27\n",
      "[0]\tvalidation_0-rmse:881.697\tvalidation_1-rmse:1071.89\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-rmse:840.504\tvalidation_1-rmse:1029.19\n",
      "[199]\tvalidation_0-rmse:276.5\tvalidation_1-rmse:389.132\n",
      "0.6492073097142486\n",
      "valid mean: 512.0814\n",
      "true  mean: 673.0143939393939\n",
      "test  mean: 391.85028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.49it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 27.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 29\n",
      "all_idx  : 13 27\n",
      "train_idx: 13 23\n",
      "valid_idx: 24 24\n",
      "test_idx : 28 28\n",
      "[0]\tvalidation_0-rmse:900.647\tvalidation_1-rmse:1451.3\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-rmse:859.319\tvalidation_1-rmse:1408.35\n",
      "[199]\tvalidation_0-rmse:282.737\tvalidation_1-rmse:801.228\n",
      "0.40110547860321266\n",
      "valid mean: 481.19583\n",
      "true  mean: 899.8204545454546\n",
      "test  mean: 382.5133\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'CCF_sales_xgb.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-2119952e6b64>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0msub_xgb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregMonth\u001b[0m\u001b[1;33m>=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m&\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregYear\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m2018\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'salesVolume'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0msub_xgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'forecastVolum'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0msub_xgb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'forecastVolum'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'CCF_sales_xgb.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\Anaconda3\\envs\\Tensorflow\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[0;32m   3227\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3228\u001b[0m         )\n\u001b[1;32m-> 3229\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3231\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\Tensorflow\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    181\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m                 \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m             )\n\u001b[0;32m    185\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\Tensorflow\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[0;32m    395\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 397\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    398\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m             \u001b[1;31m# No explicit encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'CCF_sales_xgb.csv'"
     ]
    }
   ],
   "source": [
    "for month in [25,26,27,28]: \n",
    "    m_type = 'xgb' \n",
    "    \n",
    "    data_df, stat_feat = get_stat_feature(data)\n",
    "    \n",
    "    num_feat = ['regYear'] + stat_feat\n",
    "    cate_feat = ['adcode','bodyType','model','regMonth']\n",
    "    \n",
    "    if m_type == 'lgb':\n",
    "        for i in cate_feat:\n",
    "            data_df[i] = data_df[i].astype('category')\n",
    "    elif m_type == 'xgb':\n",
    "        lbl = LabelEncoder()  \n",
    "        for i in tqdm(cate_feat):\n",
    "            data_df[i] = lbl.fit_transform(data_df[i].astype(str))\n",
    "           \n",
    "    features = num_feat + cate_feat\n",
    "    print(len(features), len(set(features)))   \n",
    "    \n",
    "    sub,val_pred = get_train_model(data_df, month, m_type)   \n",
    "    data.loc[(data.regMonth==(month-24))&(data.regYear==2018), 'salesVolume'] = sub['forecastVolum'].values\n",
    "    data.loc[(data.regMonth==(month-24))&(data.regYear==2018), 'label'      ] = sub['forecastVolum'].values\t\n",
    "sub_xgb = data.loc[(data.regMonth>=1)&(data.regYear==2018), ['id','salesVolume']]\n",
    "sub_xgb.columns = ['id','forecastVolum']\n",
    "sub_xgb[['id','forecastVolum']].round().astype(int).to_csv('CCF_sales_xgb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  3.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 29\n",
      "all_idx  : 13 24\n",
      "train_idx: 13 20\n",
      "valid_idx: 21 21\n",
      "test_idx : 25 25\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's l2: 8492.89\tvalid_1's l2: 35153.6\n",
      "[200]\ttraining's l2: 4546.93\tvalid_1's l2: 31997.7\n",
      "[300]\ttraining's l2: 2975.08\tvalid_1's l2: 31250.1\n",
      "[400]\ttraining's l2: 2097.97\tvalid_1's l2: 30863.9\n",
      "[500]\ttraining's l2: 1548.26\tvalid_1's l2: 30670.3\n",
      "[600]\ttraining's l2: 1186.17\tvalid_1's l2: 30450.2\n",
      "[700]\ttraining's l2: 941.965\tvalid_1's l2: 30312.3\n",
      "[800]\ttraining's l2: 752.927\tvalid_1's l2: 30220\n",
      "[900]\ttraining's l2: 614.003\tvalid_1's l2: 30146.6\n",
      "[1000]\ttraining's l2: 507.21\tvalid_1's l2: 30122.4\n",
      "[1100]\ttraining's l2: 417.38\tvalid_1's l2: 30072.3\n",
      "[1200]\ttraining's l2: 349.745\tvalid_1's l2: 30037.1\n",
      "[1300]\ttraining's l2: 293.352\tvalid_1's l2: 30013.1\n",
      "[1400]\ttraining's l2: 248.668\tvalid_1's l2: 30001.2\n",
      "Early stopping, best iteration is:\n",
      "[1379]\ttraining's l2: 257.61\tvalid_1's l2: 29993.3\n",
      "0.7595307137391416\n",
      "valid mean: 597.5013335217342\n",
      "true  mean: 649.3121212121212\n",
      "test  mean: 501.48727630265165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 29\n",
      "all_idx  : 13 25\n",
      "train_idx: 13 21\n",
      "valid_idx: 22 22\n",
      "test_idx : 26 26\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's l2: 9064.9\tvalid_1's l2: 42831.3\n",
      "[200]\ttraining's l2: 5011.29\tvalid_1's l2: 42129.5\n",
      "[300]\ttraining's l2: 3337\tvalid_1's l2: 41897.7\n",
      "Early stopping, best iteration is:\n",
      "[247]\ttraining's l2: 4089.85\tvalid_1's l2: 41750.9\n",
      "0.742167006506538\n",
      "valid mean: 628.5670193841313\n",
      "true  mean: 616.5537878787878\n",
      "test  mean: 333.901352665761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 29\n",
      "all_idx  : 13 26\n",
      "train_idx: 13 22\n",
      "valid_idx: 23 23\n",
      "test_idx : 27 27\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's l2: 10087\tvalid_1's l2: 33582\n",
      "[200]\ttraining's l2: 5480.63\tvalid_1's l2: 32030.1\n",
      "Early stopping, best iteration is:\n",
      "[186]\ttraining's l2: 5790.86\tvalid_1's l2: 31914.4\n",
      "0.7811053032455804\n",
      "valid mean: 643.1109390693433\n",
      "true  mean: 673.0143939393939\n",
      "test  mean: 503.69364370375354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 29\n",
      "all_idx  : 13 27\n",
      "train_idx: 13 23\n",
      "valid_idx: 24 24\n",
      "test_idx : 28 28\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's l2: 10693.1\tvalid_1's l2: 331691\n",
      "[200]\ttraining's l2: 6184.36\tvalid_1's l2: 325609\n",
      "Early stopping, best iteration is:\n",
      "[163]\ttraining's l2: 7155.93\tvalid_1's l2: 324504\n",
      "0.5975151216410015\n",
      "valid mean: 644.2463500470923\n",
      "true  mean: 899.8204545454546\n",
      "test  mean: 500.87802249387806\n"
     ]
    }
   ],
   "source": [
    "for month in [25,26,27,28]: \n",
    "    m_type = 'lgb' \n",
    "    \n",
    "    data_df, stat_feat = get_stat_feature(data)\n",
    "    \n",
    "    num_feat = ['regYear'] + stat_feat\n",
    "    cate_feat = ['adcode','bodyType','model','regMonth']\n",
    "    \n",
    "    if m_type == 'lgb':\n",
    "        for i in cate_feat:\n",
    "            data_df[i] = data_df[i].astype('category')\n",
    "    elif m_type == 'xgb':\n",
    "        lbl = LabelEncoder()  \n",
    "        for i in tqdm(cate_feat):\n",
    "            data_df[i] = lbl.fit_transform(data_df[i].astype(str))\n",
    "           \n",
    "    features = num_feat + cate_feat\n",
    "    print(len(features), len(set(features)))   \n",
    "    \n",
    "    sub,val_pred = get_train_model(data_df, month, m_type)   \n",
    "    data.loc[(data.regMonth==(month-24))&(data.regYear==2018), 'salesVolume'] = sub['forecastVolum'].values\n",
    "    data.loc[(data.regMonth==(month-24))&(data.regYear==2018), 'label'      ] = sub['forecastVolum'].values\t\n",
    "sub_lgb = data.loc[(data.regMonth>=1)&(data.regYear==2018), ['id','salesVolume']]\n",
    "sub_lgb.columns = ['id','forecastVolum']\n",
    "sub_lgb[['id','forecastVolum']].round().astype(int).to_csv('CCF_sales_lgb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_avg = pd.DataFrame()\n",
    "sub_avg['id'] = sub_xgb['id']\n",
    "sub_avg['forecastVolum'] = (sub_xgb['forecastVolum']+sub_lgb['forecastVolum'])/2\n",
    "sub_avg[['id','forecastVolum']].round().astype(int).to_csv('CCF_sales_avg.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
